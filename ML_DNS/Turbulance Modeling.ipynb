{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv3D, MaxPooling3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the tau's to be predicted\n",
    "\"\"\"\n",
    "def get_output_data():\n",
    "    tau_11 = loadmat('tau11_xyz_T1.mat')['tau11']\n",
    "    tau_12 = loadmat('tau12_xyz_T1.mat')['tau12']\n",
    "    tau_13 = loadmat('tau13_xyz_T1.mat')['tau13']\n",
    "    tau_22 = loadmat('tau22_xyz_T1.mat')['tau22']\n",
    "    tau_23 = loadmat('tau23_xyz_T1.mat')['tau23']\n",
    "    tau_33 = loadmat('tau33_xyz_T1.mat')['tau33']\n",
    "    return tau_11, tau_12, tau_13, tau_22, tau_23, tau_33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the tau's to be predicted\n",
    "\"\"\"\n",
    "def get_input_data():\n",
    "    uf = loadmat('u_F_xyz_T1.mat')['u_F']\n",
    "    vf = loadmat('v_F_xyz_T1.mat')['v_F']\n",
    "    wf = loadmat('w_F_xyz_T1.mat')['w_F']\n",
    "    return uf, vf, wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Explores Dataset\n",
    "\"\"\"\n",
    "def explore_data(data):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    # Varying by X\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(data[:,0,0])\n",
    "    # Varying by Y\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(data[0,:,0])\n",
    "    # Varying by Z\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(data[0,0,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reshapes Data and split data into train and test sets\n",
    "\"\"\"\n",
    "def create_train_test_sets(tau_11, tau_12, tau_13, tau_22, tau_23, tau_33,\n",
    "                           uf, vf, wf,\n",
    "                           train_pct):\n",
    "    x_dataset = np.transpose(np.array([uf.flatten(), vf.flatten(), wf.flatten()]))\n",
    "    tau_11_dataset = np.transpose(np.array([tau_11.flatten()]))\n",
    "    tau_12_dataset = np.transpose(np.array([tau_12.flatten()]))\n",
    "    tau_13_dataset = np.transpose(np.array([tau_13.flatten()]))\n",
    "    tau_22_dataset = np.transpose(np.array([tau_22.flatten()]))\n",
    "    tau_23_dataset = np.transpose(np.array([tau_23.flatten()]))\n",
    "    tau_33_dataset = np.transpose(np.array([tau_33.flatten()]))\n",
    "\n",
    "    print(x_dataset.shape)\n",
    "    print(tau_11_dataset.shape, tau_12_dataset.shape, tau_13_dataset.shape,\n",
    "          tau_22_dataset.shape, tau_23_dataset.shape, tau_33_dataset.shape)\n",
    "\n",
    "    train_test_index = (np.random.rand(x_dataset.shape[0]) < train_pct)\n",
    "\n",
    "    x_train, x_test = x_dataset[train_test_index,:], x_dataset[~train_test_index,:]\n",
    "\n",
    "    tau_11_train, tau_11_test = tau_11_dataset[train_test_index,:], tau_11_dataset[~train_test_index,:]\n",
    "    tau_12_train, tau_12_test = tau_12_dataset[train_test_index,:], tau_12_dataset[~train_test_index,:]\n",
    "    tau_13_train, tau_13_test = tau_13_dataset[train_test_index,:], tau_13_dataset[~train_test_index,:]\n",
    "    tau_22_train, tau_22_test = tau_22_dataset[train_test_index,:], tau_22_dataset[~train_test_index,:]\n",
    "    tau_23_train, tau_23_test = tau_23_dataset[train_test_index,:], tau_23_dataset[~train_test_index,:]\n",
    "    tau_33_train, tau_33_test = tau_33_dataset[train_test_index,:], tau_33_dataset[~train_test_index,:]\n",
    "\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    return (x_train, x_test, tau_11_train, tau_11_test, tau_12_train, tau_12_test, tau_13_train, tau_13_test,\n",
    "           tau_22_train, tau_22_test, tau_23_train, tau_23_test, tau_33_train, tau_33_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reshapes Data and split data into train and test sets (Convolutional Set up)\n",
    "\"\"\"\n",
    "def create_train_test_sets_conv3d(tau_11, tau_12, tau_13, tau_22, tau_23, tau_33,\n",
    "                                uf, vf, wf,\n",
    "                                train_pct):\n",
    "        \n",
    "    train_index = np.concatenate((np.ones((int(np.floor(uf.shape[0]*train_pct)), uf.shape[1], uf.shape[2]), dtype = 'bool'),\n",
    "                           np.zeros((int(np.ceil(uf.shape[0]*(1-train_pct))), uf.shape[1], uf.shape[2]), dtype = 'bool')),\n",
    "                           axis = 0)\n",
    "\n",
    "    print(train_index.shape)\n",
    "    \n",
    "    test_index = ~(train_index)\n",
    "    \n",
    "    train_index[0,:,:] = False\n",
    "    train_index[uf.shape[0]-1,:,:] = False\n",
    "    train_index[:,0,:] = False\n",
    "    train_index[:,uf.shape[1]-1,:] = False\n",
    "    train_index[:,:,0] = False\n",
    "    train_index[:,:,uf.shape[2]-1] = False\n",
    "    test_index[0,:,:] = False\n",
    "    test_index[uf.shape[0]-1,:,:] = False\n",
    "    test_index[:,0,:] = False\n",
    "    test_index[:,uf.shape[1]-1,:] = False\n",
    "    test_index[:,:,0] = False\n",
    "    test_index[:,:,uf.shape[2]-1] = False\n",
    "    \n",
    "    train_locs = np.where(train_index)\n",
    "    test_locs = np.where(test_index)\n",
    "    \n",
    "    print(train_locs)\n",
    "    \n",
    "    tau_11_train, tau_11_test = np.transpose([tau_11[train_locs]]), np.transpose([tau_11[test_locs]])\n",
    "    tau_12_train, tau_12_test = np.transpose([tau_12[train_locs]]), np.transpose([tau_12[test_locs]])\n",
    "    tau_13_train, tau_13_test = np.transpose([tau_13[train_locs]]), np.transpose([tau_13[test_locs]])\n",
    "    tau_22_train, tau_22_test = np.transpose([tau_22[train_locs]]), np.transpose([tau_22[test_locs]])\n",
    "    tau_23_train, tau_23_test = np.transpose([tau_23[train_locs]]), np.transpose([tau_23[test_locs]])\n",
    "    tau_33_train, tau_33_test = np.transpose([tau_33[train_locs]]), np.transpose([tau_33[test_locs]])\n",
    "    \n",
    "    x_train = np.array([np.stack([uf[(x-1):(x+2),(y-1):(y+2),(z-1):(z+2)],\n",
    "                                  vf[(x-1):(x+2),(y-1):(y+2),(z-1):(z+2)],\n",
    "                                  wf[(x-1):(x+2),(y-1):(y+2),(z-1):(z+2)]], axis = 3)\n",
    "              for x,y,z in zip(train_locs[0], train_locs[1], train_locs[2])])\n",
    "    \n",
    "    x_test = np.array([np.stack([uf[(x-1):(x+2),(y-1):(y+2),(z-1):(z+2)],\n",
    "                                  vf[(x-1):(x+2),(y-1):(y+2),(z-1):(z+2)],\n",
    "                                  wf[(x-1):(x+2),(y-1):(y+2),(z-1):(z+2)]], axis = 3)\n",
    "              for x,y,z in zip(test_locs[0], test_locs[1], test_locs[2])])\n",
    "\n",
    "    print('X_train shape', x_train.shape)\n",
    "    print('tau_train shape', tau_11_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    return (x_train, x_test, tau_11_train, tau_11_test, tau_12_train, tau_12_test, tau_13_train, tau_13_test,\n",
    "           tau_22_train, tau_22_test, tau_23_train, tau_23_test, tau_33_train, tau_33_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains Simple One-Layer Neural Network with Relu Activation Functions\n",
    "\"\"\"\n",
    "def train_simple_nn_model(x_train, x_test, y_train, y_test, act_func = 'tanh',\n",
    "                          batch_size = 20, epochs = 20, num_nodes = 10, xdim = 3):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_nodes, activation=act_func, input_shape=(xdim,)))\n",
    "    model.add(Dense(1, activation=act_func, input_shape=(xdim,)))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=[metrics.mse])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains Two-Layer Neural Network with Relu Activation Functions\n",
    "\"\"\"\n",
    "def train_two_layer_nn_model(x_train, x_test, y_train, y_test, act_func = 'tanh',\n",
    "                             batch_size = 128, epochs = 20, num_nodes = (10,10), xdim = 3):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_nodes[0], activation=act_func, input_shape=(xdim,)))\n",
    "    model.add(Dense(num_nodes[1], activation=act_func))\n",
    "    model.add(Dense(1, activation=act_func))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=SGD(),\n",
    "                  metrics=[metrics.mse])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains Two-Layer Neural Network with Relu Activation Functions\n",
    "\"\"\"\n",
    "def train_conv_3d_model(x_train, x_test, y_train, y_test, act_func = 'tanh',\n",
    "                          batch_size = 128, epochs = 20, num_nodes = 6, xdim = 3):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(128, kernel_size = (3,3,3), data_format = 'channels_last',\n",
    "                     input_shape = x_train.shape[1:], kernel_initializer = 'random_uniform'))\n",
    "    model.add(Activation(act_func))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation = act_func))\n",
    "    model.add(Dense(1, activation = act_func))\n",
    "    \n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=SGD(),\n",
    "                  metrics=[metrics.mse])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots Actual vs. Predicted Values from Model\n",
    "\"\"\"\n",
    "def predict_and_visualize(model, x_test, y_test):\n",
    "    y_predict = model.predict(x_test)\n",
    "    sample_index = (np.random.rand(y_test.shape[0]) < 1000./y_test.shape[0])\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(y_test[sample_index])\n",
    "    plt.plot(y_predict[sample_index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'one-layer NN': (create_train_test_sets, train_simple_nn_model),\n",
    "          'two-layer NN': (create_train_test_sets, train_two_layer_nn_model),\n",
    "          'conv-3d NN': (create_train_test_sets_conv3d, train_conv_3d_model)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots Actual vs. Predicted Values from Model\n",
    "\"\"\"\n",
    "def predict_and_visualize(model, x_test, y_test):\n",
    "    y_predict = model.predict(x_test)\n",
    "    sample_index = (np.random.rand(y_test.shape[0]) < 1000./y_test.shape[0])\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(y_test[sample_index])\n",
    "    plt.plot(y_predict[sample_index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots Actual vs. Predicted Values from Model\n",
    "\"\"\"\n",
    "def predict(model, x_test, y_test):\n",
    "    y_test = y_test.flatten()\n",
    "    y_predict = model.predict(x_test).flatten()\n",
    "    return np.corrcoef(y_test, y_predict), np.sqrt(((y_test - y_predict) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main Function to Execute Model\n",
    "\"\"\"\n",
    "def main(model_name):\n",
    "    \n",
    "    # Output Data\n",
    "    tau_11, tau_12, tau_13, tau_22,tau_23, tau_33 = get_output_data()\n",
    "    print('Shape of Output Files:')\n",
    "    print(tau_11.shape, tau_12.shape, tau_13.shape, tau_22.shape, tau_23.shape, tau_33.shape)\n",
    "    \n",
    "    # Input Data\n",
    "    uf, vf, wf = get_input_data()\n",
    "    print('Shape of Input Files:')\n",
    "    print(uf.shape, vf.shape, wf.shape)\n",
    "    \n",
    "    # Explore Data\n",
    "    #explore_data(tau_12)\n",
    "    \n",
    "    # Get Functions\n",
    "    train_test_split_func, model_func = models[model_name]\n",
    "    \n",
    "    # Reshape Data and Get Train/Test Sets\n",
    "    (x_train, x_test, tau_11_train, \n",
    "    tau_11_test, tau_12_train, tau_12_test, tau_13_train, tau_13_test,\n",
    "    tau_22_train, tau_22_test, tau_23_train, tau_23_test, \n",
    "    tau_33_train, tau_33_test) = train_test_split_func(tau_11, tau_12, tau_13, tau_22, tau_23, \n",
    "                                                       tau_33,uf, vf, wf, train_pct = 0.5)\n",
    "    \n",
    "    print(x_train[0,:])\n",
    "    print(tau_11_train[0,:])\n",
    "    \n",
    "    # Train the Model\n",
    "    models_final = [model_func(x_train, x_test, tau_11_train, tau_11_test, act_func = 'relu'),\n",
    "                    model_func(x_train, x_test, tau_12_train, tau_12_test, act_func = 'tanh'),\n",
    "                    model_func(x_train, x_test, tau_13_train, tau_13_test, act_func = 'tanh'),\n",
    "                    model_func(x_train, x_test, tau_22_train, tau_22_test, act_func = 'relu'),\n",
    "                    model_func(x_train, x_test, tau_23_train, tau_23_test, act_func = 'tanh'),\n",
    "                    model_func(x_train, x_test, tau_33_train, tau_33_test, act_func = 'relu')]\n",
    "    \n",
    "    # Visualize Results\n",
    "    results = [predict(models_final[0], x_test, tau_11_test),\n",
    "               predict(models_final[1], x_test, tau_12_test),\n",
    "               predict(models_final[2], x_test, tau_13_test),\n",
    "               predict(models_final[3], x_test, tau_22_test),\n",
    "               predict(models_final[4], x_test, tau_23_test),\n",
    "               predict(models_final[5], x_test, tau_33_test)]\n",
    "    \n",
    "    return models_final, results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Output Files:\n",
      "(146, 96, 75) (146, 96, 75) (146, 96, 75) (146, 96, 75) (146, 96, 75) (146, 96, 75)\n",
      "Shape of Input Files:\n",
      "(146, 96, 75) (146, 96, 75) (146, 96, 75)\n",
      "(1051200, 3)\n",
      "(1051200, 1) (1051200, 1) (1051200, 1) (1051200, 1) (1051200, 1) (1051200, 1)\n",
      "525435 train samples\n",
      "525765 test samples\n",
      "[ 0.61426491  0.35302837 -0.41810399]\n",
      "[0.04341826]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_205 (Dense)            (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 525435 samples, validate on 525765 samples\n",
      "Epoch 1/20\n",
      "525435/525435 [==============================] - 11s 21us/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 9.4320e-04 - val_mean_squared_error: 9.4320e-04an_squ\n",
      "Epoch 2/20\n",
      "525435/525435 [==============================] - 11s 20us/step - loss: 9.4636e-04 - mean_squared_error: 9.4636e-04 - val_loss: 9.4177e-04 - val_mean_squared_error: 9.4177e-04\n",
      "Epoch 3/20\n",
      "525435/525435 [==============================] - 10s 20us/step - loss: 9.4575e-04 - mean_squared_error: 9.4575e-04 - val_loss: 9.4146e-04 - val_mean_squared_error: 9.4146e-04\n",
      "Epoch 4/20\n",
      "525435/525435 [==============================] - 10s 20us/step - loss: 9.4558e-04 - mean_squared_error: 9.4558e-04 - val_loss: 9.4134e-04 - val_mean_squared_error: 9.4134e-04\n",
      "Epoch 5/20\n",
      "525435/525435 [==============================] - 10s 20us/step - loss: 9.4551e-04 - mean_squared_error: 9.4551e-04 - val_loss: 9.4129e-04 - val_mean_squared_error: 9.4129e-04 - loss: 9.4407e-04 - mean_squared_err\n",
      "Epoch 6/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 9.4548e-04 - mean_squared_error: 9.4548e-04 - val_loss: 9.4126e-04 - val_mean_squared_error: 9.4126e-04\n",
      "Epoch 7/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.4546e-04 - mean_squared_error: 9.4546e-04 - val_loss: 9.4124e-04 - val_mean_squared_error: 9.4124e-04\n",
      "Epoch 8/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.4545e-04 - mean_squared_error: 9.4545e-04 - val_loss: 9.4123e-04 - val_mean_squared_error: 9.4123e-04\n",
      "Epoch 9/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.4545e-04 - mean_squared_error: 9.4545e-04 - val_loss: 9.4122e-04 - val_mean_squared_error: 9.4122e-04\n",
      "Epoch 10/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.4544e-04 - mean_squared_error: 9.4544e-04 - val_loss: 9.4121e-04 - val_mean_squared_error: 9.4121e-04\n",
      "Epoch 11/20\n",
      "525435/525435 [==============================] - 10s 20us/step - loss: 9.4544e-04 - mean_squared_error: 9.4544e-04 - val_loss: 9.4121e-04 - val_mean_squared_error: 9.4121e-04\n",
      "Epoch 12/20\n",
      "525435/525435 [==============================] - 12s 23us/step - loss: 9.4543e-04 - mean_squared_error: 9.4543e-04 - val_loss: 9.4120e-04 - val_mean_squared_error: 9.4120e-04\n",
      "Epoch 13/20\n",
      "525435/525435 [==============================] - 11s 21us/step - loss: 9.4543e-04 - mean_squared_error: 9.4543e-04 - val_loss: 9.4120e-04 - val_mean_squared_error: 9.4120e-04\n",
      "Epoch 14/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.4543e-04 - mean_squared_error: 9.4543e-04 - val_loss: 9.4120e-04 - val_mean_squared_error: 9.4120e-04\n",
      "Epoch 15/20\n",
      "525435/525435 [==============================] - 10s 18us/step - loss: 9.4543e-04 - mean_squared_error: 9.4543e-04 - val_loss: 9.4119e-04 - val_mean_squared_error: 9.4119e-04\n",
      "Epoch 16/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.4543e-04 - mean_squared_error: 9.4543e-04 - val_loss: 9.4119e-04 - val_mean_squared_error: 9.4119e-04\n",
      "Epoch 17/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.4543e-04 - mean_squared_error: 9.4543e-04 - val_loss: 9.4119e-04 - val_mean_squared_error: 9.4119e-044509e-04 - \n",
      "Epoch 18/20\n",
      "525435/525435 [==============================] - 12s 23us/step - loss: 9.4542e-04 - mean_squared_error: 9.4542e-04 - val_loss: 9.4119e-04 - val_mean_squared_error: 9.4119e-04\n",
      "Epoch 19/20\n",
      "525435/525435 [==============================] - 10s 18us/step - loss: 9.4542e-04 - mean_squared_error: 9.4542e-04 - val_loss: 9.4119e-04 - val_mean_squared_error: 9.4119e-04\n",
      "Epoch 20/20\n",
      "525435/525435 [==============================] - 12s 23us/step - loss: 9.4542e-04 - mean_squared_error: 9.4542e-04 - val_loss: 9.4119e-04 - val_mean_squared_error: 9.4119e-04\n",
      "Test loss: 0.000941185488791535\n",
      "Test accuracy: 0.000941185488791535\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_208 (Dense)            (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 525435 samples, validate on 525765 samples\n",
      "Epoch 1/20\n",
      "525435/525435 [==============================] - 13s 25us/step - loss: 2.9006e-04 - mean_squared_error: 2.9006e-04 - val_loss: 1.0117e-04 - val_mean_squared_error: 1.0117e-04\n",
      "Epoch 2/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 9.8916e-05 - mean_squared_error: 9.8916e-05 - val_loss: 9.8523e-05 - val_mean_squared_error: 9.8523e-05\n",
      "Epoch 3/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 9.7504e-05 - mean_squared_error: 9.7504e-05 - val_loss: 9.7620e-05 - val_mean_squared_error: 9.7620e-05\n",
      "Epoch 4/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 9.6612e-05 - mean_squared_error: 9.6612e-05 - val_loss: 9.6756e-05 - val_mean_squared_error: 9.6756e-05\n",
      "Epoch 5/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 9.5821e-05 - mean_squared_error: 9.5821e-05 - val_loss: 9.6024e-05 - val_mean_squared_error: 9.6024e-05\n",
      "Epoch 6/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 9.5115e-05 - mean_squared_error: 9.5115e-05 - val_loss: 9.5376e-05 - val_mean_squared_error: 9.5376e-05\n",
      "Epoch 7/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 9.4478e-05 - mean_squared_error: 9.4478e-05 - val_loss: 9.4757e-05 - val_mean_squared_error: 9.4757e-05\n",
      "Epoch 8/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 9.3909e-05 - mean_squared_error: 9.3909e-05 - val_loss: 9.4180e-05 - val_mean_squared_error: 9.4180e-05\n",
      "Epoch 9/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.3386e-05 - mean_squared_error: 9.3386e-05 - val_loss: 9.3746e-05 - val_mean_squared_error: 9.3746e-05\n",
      "Epoch 10/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 9.2916e-05 - mean_squared_error: 9.2916e-05 - val_loss: 9.3241e-05 - val_mean_squared_error: 9.3241e-05\n",
      "Epoch 11/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.2492e-05 - mean_squared_error: 9.2492e-05 - val_loss: 9.2798e-05 - val_mean_squared_error: 9.2798e-05\n",
      "Epoch 12/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.2088e-05 - mean_squared_error: 9.2088e-05 - val_loss: 9.2448e-05 - val_mean_squared_error: 9.2448e-05\n",
      "Epoch 13/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.1729e-05 - mean_squared_error: 9.1729e-05 - val_loss: 9.2070e-05 - val_mean_squared_error: 9.2070e-05\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.1390e-05 - mean_squared_error: 9.1390e-05 - val_loss: 9.1748e-05 - val_mean_squared_error: 9.1748e-05\n",
      "Epoch 15/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 9.1090e-05 - mean_squared_error: 9.1090e-05 - val_loss: 9.1448e-05 - val_mean_squared_error: 9.1448e-05\n",
      "Epoch 16/20\n",
      "525435/525435 [==============================] - 9s 16us/step - loss: 9.0799e-05 - mean_squared_error: 9.0799e-05 - val_loss: 9.1170e-05 - val_mean_squared_error: 9.1170e-05\n",
      "Epoch 17/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.0530e-05 - mean_squared_error: 9.0530e-05 - val_loss: 9.0960e-05 - val_mean_squared_error: 9.0960e-05\n",
      "Epoch 18/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.0284e-05 - mean_squared_error: 9.0284e-05 - val_loss: 9.0725e-05 - val_mean_squared_error: 9.0725e-05\n",
      "Epoch 19/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.0055e-05 - mean_squared_error: 9.0055e-05 - val_loss: 9.0481e-05 - val_mean_squared_error: 9.0481e-05\n",
      "Epoch 20/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 8.9830e-05 - mean_squared_error: 8.9830e-05 - val_loss: 9.0261e-05 - val_mean_squared_error: 9.0261e-05\n",
      "Test loss: 9.026085957362409e-05\n",
      "Test accuracy: 9.026085957362409e-05\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_211 (Dense)            (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 525435 samples, validate on 525765 samples\n",
      "Epoch 1/20\n",
      "525435/525435 [==============================] - 11s 21us/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 3.4989e-04 - val_mean_squared_error: 3.4989e-04ared_error: 0. - ETA: 1s - loss: 0.0 - ETA: 0s - loss: 0.0017 - mean_s\n",
      "Epoch 2/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 2.9229e-04 - mean_squared_error: 2.9229e-04 - val_loss: 2.6657e-04 - val_mean_squared_error: 2.6657e-04\n",
      "Epoch 3/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 2.6144e-04 - mean_squared_error: 2.6144e-04 - val_loss: 2.5996e-04 - val_mean_squared_error: 2.5996e-04\n",
      "Epoch 4/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 2.5877e-04 - mean_squared_error: 2.5877e-04 - val_loss: 2.5905e-04 - val_mean_squared_error: 2.5905e-04\n",
      "Epoch 5/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 2.5841e-04 - mean_squared_error: 2.5841e-04 - val_loss: 2.5891e-04 - val_mean_squared_error: 2.5891e-04\n",
      "Epoch 6/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.5828e-04 - mean_squared_error: 2.5828e-04 - val_loss: 2.5881e-04 - val_mean_squared_error: 2.5881e-04\n",
      "Epoch 7/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 2.5818e-04 - mean_squared_error: 2.5818e-04 - val_loss: 2.5869e-04 - val_mean_squared_error: 2.5869e-04\n",
      "Epoch 8/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 2.5808e-04 - mean_squared_error: 2.5808e-04 - val_loss: 2.5880e-04 - val_mean_squared_error: 2.5880e-04\n",
      "Epoch 9/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 2.5798e-04 - mean_squared_error: 2.5798e-04 - val_loss: 2.5879e-04 - val_mean_squared_error: 2.5879e-04\n",
      "Epoch 10/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 2.5791e-04 - mean_squared_error: 2.5791e-04 - val_loss: 2.5850e-04 - val_mean_squared_error: 2.5850e-04\n",
      "Epoch 11/20\n",
      "525435/525435 [==============================] - 9s 16us/step - loss: 2.5784e-04 - mean_squared_error: 2.5784e-04 - val_loss: 2.5840e-04 - val_mean_squared_error: 2.5840e-04\n",
      "Epoch 12/20\n",
      "525435/525435 [==============================] - 10s 18us/step - loss: 2.5776e-04 - mean_squared_error: 2.5776e-04 - val_loss: 2.5823e-04 - val_mean_squared_error: 2.5823e-04\n",
      "Epoch 13/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.5769e-04 - mean_squared_error: 2.5769e-04 - val_loss: 2.5876e-04 - val_mean_squared_error: 2.5876e-04\n",
      "Epoch 14/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 2.5762e-04 - mean_squared_error: 2.5762e-04 - val_loss: 2.5813e-04 - val_mean_squared_error: 2.5813e-04\n",
      "Epoch 15/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.5758e-04 - mean_squared_error: 2.5758e-04 - val_loss: 2.5803e-04 - val_mean_squared_error: 2.5803e-04\n",
      "Epoch 16/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.5750e-04 - mean_squared_error: 2.5750e-04 - val_loss: 2.5805e-04 - val_mean_squared_error: 2.5805e-04\n",
      "Epoch 17/20\n",
      "525435/525435 [==============================] - 9s 16us/step - loss: 2.5745e-04 - mean_squared_error: 2.5745e-04 - val_loss: 2.5793e-04 - val_mean_squared_error: 2.5793e-04\n",
      "Epoch 18/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 2.5741e-04 - mean_squared_error: 2.5741e-04 - val_loss: 2.5789e-04 - val_mean_squared_error: 2.5789e-04\n",
      "Epoch 19/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 2.5737e-04 - mean_squared_error: 2.5737e-04 - val_loss: 2.5790e-04 - val_mean_squared_error: 2.5790e-04\n",
      "Epoch 20/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.5732e-04 - mean_squared_error: 2.5732e-04 - val_loss: 2.5780e-04 - val_mean_squared_error: 2.5780e-04\n",
      "Test loss: 0.0002578017513789263\n",
      "Test accuracy: 0.0002578017513789263\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_214 (Dense)            (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 525435 samples, validate on 525765 samples\n",
      "Epoch 1/20\n",
      "525435/525435 [==============================] - 11s 21us/step - loss: 9.9121e-04 - mean_squared_error: 9.9121e-04 - val_loss: 9.3835e-04 - val_mean_squared_error: 9.3835e-04\n",
      "Epoch 2/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.4017e-04 - mean_squared_error: 9.4017e-04 - val_loss: 9.3499e-04 - val_mean_squared_error: 9.3499e-04\n",
      "Epoch 3/20\n",
      "525435/525435 [==============================] - 12s 22us/step - loss: 9.3830e-04 - mean_squared_error: 9.3830e-04 - val_loss: 9.3377e-04 - val_mean_squared_error: 9.3377e-04\n",
      "Epoch 4/20\n",
      "525435/525435 [==============================] - 11s 22us/step - loss: 9.3748e-04 - mean_squared_error: 9.3748e-04 - val_loss: 9.3311e-04 - val_mean_squared_error: 9.3311e-04\n",
      "Epoch 5/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 9.3701e-04 - mean_squared_error: 9.3701e-04 - val_loss: 9.3273e-04 - val_mean_squared_error: 9.3273e-04\n",
      "Epoch 6/20\n",
      "525435/525435 [==============================] - 9s 16us/step - loss: 9.3672e-04 - mean_squared_error: 9.3672e-04 - val_loss: 9.3247e-04 - val_mean_squared_error: 9.3247e-04\n",
      "Epoch 7/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.3652e-04 - mean_squared_error: 9.3652e-04 - val_loss: 9.3229e-04 - val_mean_squared_error: 9.3229e-04\n",
      "Epoch 8/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.3638e-04 - mean_squared_error: 9.3638e-04 - val_loss: 9.3216e-04 - val_mean_squared_error: 9.3216e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.3627e-04 - mean_squared_error: 9.3627e-04 - val_loss: 9.3206e-04 - val_mean_squared_error: 9.3206e-04\n",
      "Epoch 10/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.3618e-04 - mean_squared_error: 9.3618e-04 - val_loss: 9.3199e-04 - val_mean_squared_error: 9.3199e-04\n",
      "Epoch 11/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.3611e-04 - mean_squared_error: 9.3611e-04 - val_loss: 9.3192e-04 - val_mean_squared_error: 9.3192e-04\n",
      "Epoch 12/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.3605e-04 - mean_squared_error: 9.3605e-04 - val_loss: 9.3188e-04 - val_mean_squared_error: 9.3188e-04\n",
      "Epoch 13/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 9.3600e-04 - mean_squared_error: 9.3600e-04 - val_loss: 9.3184e-04 - val_mean_squared_error: 9.3184e-04\n",
      "Epoch 14/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.3596e-04 - mean_squared_error: 9.3596e-04 - val_loss: 9.3180e-04 - val_mean_squared_error: 9.3180e-04\n",
      "Epoch 15/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.3592e-04 - mean_squared_error: 9.3592e-04 - val_loss: 9.3177e-04 - val_mean_squared_error: 9.3177e-04\n",
      "Epoch 16/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 9.3589e-04 - mean_squared_error: 9.3589e-04 - val_loss: 9.3175e-04 - val_mean_squared_error: 9.3175e-04\n",
      "Epoch 17/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 9.3586e-04 - mean_squared_error: 9.3586e-04 - val_loss: 9.3173e-04 - val_mean_squared_error: 9.3173e-04\n",
      "Epoch 18/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 9.3584e-04 - mean_squared_error: 9.3584e-04 - val_loss: 9.3171e-04 - val_mean_squared_error: 9.3171e-04\n",
      "Epoch 19/20\n",
      "525435/525435 [==============================] - 11s 22us/step - loss: 9.3582e-04 - mean_squared_error: 9.3582e-04 - val_loss: 9.3170e-04 - val_mean_squared_error: 9.3170e-04\n",
      "Epoch 20/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 9.3581e-04 - mean_squared_error: 9.3581e-04 - val_loss: 9.3168e-04 - val_mean_squared_error: 9.3168e-04\n",
      "Test loss: 0.0009316826445458354\n",
      "Test accuracy: 0.0009316826445458354\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_217 (Dense)            (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 525435 samples, validate on 525765 samples\n",
      "Epoch 1/20\n",
      "525435/525435 [==============================] - 12s 23us/step - loss: 4.5915e-04 - mean_squared_error: 4.5915e-04 - val_loss: 2.8003e-04 - val_mean_squared_error: 2.8003e-04\n",
      "Epoch 2/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 2.7882e-04 - mean_squared_error: 2.7882e-04 - val_loss: 2.7726e-04 - val_mean_squared_error: 2.7726e-04\n",
      "Epoch 3/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 2.7630e-04 - mean_squared_error: 2.7630e-04 - val_loss: 2.7487e-04 - val_mean_squared_error: 2.7487e-04\n",
      "Epoch 4/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 2.7418e-04 - mean_squared_error: 2.7418e-04 - val_loss: 2.7297e-04 - val_mean_squared_error: 2.7297e-04\n",
      "Epoch 5/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 2.7233e-04 - mean_squared_error: 2.7233e-04 - val_loss: 2.7120e-04 - val_mean_squared_error: 2.7120e-04s - loss: 2.7224e-04 - mean_squared_error: \n",
      "Epoch 6/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 2.7072e-04 - mean_squared_error: 2.7072e-04 - val_loss: 2.7065e-04 - val_mean_squared_error: 2.7065e-04\n",
      "Epoch 7/20\n",
      "525435/525435 [==============================] - 10s 18us/step - loss: 2.6930e-04 - mean_squared_error: 2.6930e-04 - val_loss: 2.6867e-04 - val_mean_squared_error: 2.6867e-04\n",
      "Epoch 8/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.6804e-04 - mean_squared_error: 2.6804e-04 - val_loss: 2.6742e-04 - val_mean_squared_error: 2.6742e-04\n",
      "Epoch 9/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.6688e-04 - mean_squared_error: 2.6688e-04 - val_loss: 2.6623e-04 - val_mean_squared_error: 2.6623e-04\n",
      "Epoch 10/20\n",
      "525435/525435 [==============================] - 9s 18us/step - loss: 2.6589e-04 - mean_squared_error: 2.6589e-04 - val_loss: 2.6533e-04 - val_mean_squared_error: 2.6533e-04\n",
      "Epoch 11/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.6497e-04 - mean_squared_error: 2.6497e-04 - val_loss: 2.6496e-04 - val_mean_squared_error: 2.6496e-04\n",
      "Epoch 12/20\n",
      "525435/525435 [==============================] - 9s 17us/step - loss: 2.6416e-04 - mean_squared_error: 2.6416e-04 - val_loss: 2.6362e-04 - val_mean_squared_error: 2.6362e-04\n",
      "Epoch 13/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 2.6341e-04 - mean_squared_error: 2.6341e-04 - val_loss: 2.6297e-04 - val_mean_squared_error: 2.6297e-04\n",
      "Epoch 14/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 2.6273e-04 - mean_squared_error: 2.6273e-04 - val_loss: 2.6229e-04 - val_mean_squared_error: 2.6229e-04\n",
      "Epoch 15/20\n",
      "525435/525435 [==============================] - 12s 22us/step - loss: 2.6210e-04 - mean_squared_error: 2.6210e-04 - val_loss: 2.6185e-04 - val_mean_squared_error: 2.6185e-04\n",
      "Epoch 16/20\n",
      "525435/525435 [==============================] - 13s 26us/step - loss: 2.6157e-04 - mean_squared_error: 2.6157e-04 - val_loss: 2.6128e-04 - val_mean_squared_error: 2.6128e-04\n",
      "Epoch 17/20\n",
      "525435/525435 [==============================] - 11s 21us/step - loss: 2.6103e-04 - mean_squared_error: 2.6103e-04 - val_loss: 2.6080e-04 - val_mean_squared_error: 2.6080e-04\n",
      "Epoch 18/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 2.6057e-04 - mean_squared_error: 2.6057e-04 - val_loss: 2.6079e-04 - val_mean_squared_error: 2.6079e-04\n",
      "Epoch 19/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 2.6013e-04 - mean_squared_error: 2.6013e-04 - val_loss: 2.5986e-04 - val_mean_squared_error: 2.5986e-04 -\n",
      "Epoch 20/20\n",
      "525435/525435 [==============================] - 10s 18us/step - loss: 2.5973e-04 - mean_squared_error: 2.5973e-04 - val_loss: 2.5951e-04 - val_mean_squared_error: 2.5951e-04\n",
      "Test loss: 0.00025951336721121733\n",
      "Test accuracy: 0.00025951336721121733\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 525435 samples, validate on 525765 samples\n",
      "Epoch 1/20\n",
      "525435/525435 [==============================] - 10s 19us/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 2/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 3/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 5/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 6/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 7/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 8/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 9/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 10/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 11/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 12/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 13/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 14/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 15/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 16/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 17/20\n",
      "525435/525435 [==============================] - 8s 15us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 18/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 19/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 20/20\n",
      "525435/525435 [==============================] - 8s 16us/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Test loss: 0.0021853590136153758\n",
      "Test accuracy: 0.0021853590136153758\n"
     ]
    }
   ],
   "source": [
    "model_nn_1, results_nn_1 = main('one-layer NN')\n",
    "model_nn_2, results_nn_2 = main('two-layer NN')\n",
    "model_conv_3d, results_conv_3d = main('conv-3d NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[1.        , 0.66392491],\n",
       "         [0.66392491, 1.        ]]), 0.019077221368526857),\n",
       " (array([[ 1.        , -0.01674562],\n",
       "         [-0.01674562,  1.        ]]), 0.009428897983255155),\n",
       " (array([[1.        , 0.12001598],\n",
       "         [0.12001598, 1.        ]]), 0.016034559925569295),\n",
       " (array([[1.        , 0.66578601],\n",
       "         [0.66578601, 1.        ]]), 0.018875876372183832),\n",
       " (array([[1.        , 0.08084369],\n",
       "         [0.08084369, 1.        ]]), 0.01591807086987144),\n",
       " (array([[1.        , 0.60346868],\n",
       "         [0.60346868, 1.        ]]), 0.043272076305551896)]"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[1.00000000e+00, 8.58394439e-04],\n",
       "         [8.58394439e-04, 1.00000000e+00]]), 0.030678746548232546),\n",
       " (array([[1.        , 0.00607609],\n",
       "         [0.00607609, 1.        ]]), 0.009500571539990942),\n",
       " (array([[1.        , 0.10756245],\n",
       "         [0.10756245, 1.        ]]), 0.01605620601876627),\n",
       " (array([[1.        , 0.00232454],\n",
       "         [0.00232454, 1.        ]]), 0.030523476959390655),\n",
       " (array([[1.        , 0.04483455],\n",
       "         [0.04483455, 1.        ]]), 0.016109418593734496),\n",
       " (array([[1.        , 0.50282927],\n",
       "         [0.50282927, 1.        ]]), 0.046747823786944295)]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_nn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[1.        , 0.82924367],\n",
       "         [0.82924367, 1.        ]]), 0.014053878766919289),\n",
       " (array([[1.       , 0.1616044],\n",
       "         [0.1616044, 1.       ]]), 0.010007654023772862),\n",
       " (array([[1.        , 0.30826604],\n",
       "         [0.30826604, 1.        ]]), 0.015735410668644874),\n",
       " (array([[1.       , 0.8364762],\n",
       "         [0.8364762, 1.       ]]), 0.01379606574967823),\n",
       " (array([[1.        , 0.41828521],\n",
       "         [0.41828521, 1.        ]]), 0.015750913407546335),\n",
       " (array([[1.        , 0.87821444],\n",
       "         [0.87821444, 1.        ]]), 0.02630394266160002)]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_conv_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
